The author builds a neural network structure from scratch, including: 

- Multiple Hidden Layers
- Kaiming Initialization
- Weight Decay
- Batch Normalization
- Dropout
- Label Smoothing
- ReLU Activation Function
- Tanh Activation Function
- GELU Activation Function
- Softmax and Cross-entropy Loss
- Momentum in SGD
- Adam Optimizer
- Mini-batch Training