{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95738be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "HUGGING_FACE_API_KEY=\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"google/flan-t5-large\",\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.3,\n",
    "        \"max_length\":200},\n",
    "    huggingfacehub_api_token='<your_API_token>')\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "prompt = PromptTemplate(\n",
    "   input_variables=[\"message\"],\n",
    "   template=\"{message}\")\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "chain.predict(message=\"Hi Bot!\")\n",
    "template = \"\"\"\n",
    "    This is a conversation between a human and a\n",
    "    chatbot. The chatbot is friendly and provides\n",
    "    answers based on the previous conversation and\n",
    "    the context.\n",
    "    Human says: {message}\n",
    "    Chatbot responds:\n",
    "    \"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables = [\"message\"],  # <1>\n",
    "    template=template)\n",
    "chain = LLMChain(\n",
    "    llm=llm, verbose=True, prompt=prompt  # <2>\n",
    "    )\n",
    "chain.predict(message=\"Hi Bot! My name is Maria.\")\n",
    "chain.predict(message=\"What is my name?\")\n",
    "template = \"\"\"\n",
    "    This is a conversation between a human and a chatbot.\n",
    "    The chatbot is friendly and provides answers based\n",
    "    on the previous conversation and the context.\"\n",
    "    {chat_history}\n",
    "    Human says: {message}\n",
    "    Chatbot responds:\"\"\"\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key='chat_history')  # <1>\n",
    "chain = LLMChain(llm=llm, memory=memory, prompt=prompt)\n",
    "convo_chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory = ConversationBufferMemory\n",
    "    )\n",
    "convo_chain.prompt.template\n",
    "chain.predict(message=\"Hi chatbot! My name is Maria\")\n",
    "chain.predict(message=\"What is my name?\")\n",
    "message = \"\"\"\n",
    "    I have a brother Sergey.\n",
    "    He and his wife Olga live in Tel Aviv.\n",
    "    What's the name of my sister-in-law?\"\"\"\n",
    "chain.predict(message=message)\n",
    "from langchain.llms import Replicate\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = '<your_API_key_here>'\n",
    "llm = Replicate(\n",
    "    model=\"a16z-infra/llama13b-v2-chat:\" +\n",
    "    \"df7690\",  # <1>\n",
    "    input={\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_length\": 350,\n",
    "        \"top_p\": 1,\n",
    "    })\n",
    "prompt = PromptTemplate(\n",
    "    input_variables = [\"history\", \"input\"],\n",
    "    template=\"\"\"This is a conversation between a math teacher and\n",
    "    a third-grade student. The teacher asks math questions of the\n",
    "    student and evaluates the student's answer one at a time.\n",
    "    Complete the conversation with only one response at a time.\n",
    "    {history}\n",
    "    student:{input}\n",
    "    teacher:\"\"\")\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key='history',\n",
    "    ai_prefix='teacher',  # <1>\n",
    "    human_prefix='student',  # <2>\n",
    "    )\n",
    "memory.save_context(\n",
    "    {\"input\": \"Ask me math questions!\"},\n",
    "    {\"output\": \"Sure, let's do it! 9,10,11?\"})\n",
    "memory.save_context(\n",
    "    {\"input\": \"12\"},\n",
    "    {\"output\": \"Perfect! 38,39,40?\"})\n",
    "memory.save_context(\n",
    "    {\"input\": \"42\"},\n",
    "    {\"output\": \"Oops. Not quite. Try again.\"})\n",
    "memory.save_context(\n",
    "    {\"input\": \"41\"},\n",
    "    {\"output\": \"Good work! 2,4,6?\"})\n",
    "math_convo = ConversationChain(llm=llm, memory=memory)\n",
    "math_convo.prompt = prompt\n",
    "math_convo.predict(input=\"9\")\n",
    "math_convo = ConversationChain(\n",
    "    llm=llm, memory=memory)  # <1>\n",
    "math_convo.predict(input=\"9\")\n",
    "prompt = PromptTemplate(\n",
    "   input_variables=[\"history\", \"input\"],\n",
    "   template=\"\"\"You are a math teacher that's teaching math\n",
    "   to a third-grade student.Prompt the student to complete number\n",
    "   sequences from the following list and compare their answer\n",
    "   with the last number in the following sequences:\n",
    "     - 9,10,11,12\n",
    "     - 38,39,40,41\n",
    "     - 2,4,6,8\n",
    "     - 1,5,9,13\n",
    "   {history}\n",
    "   student:{input}\n",
    "   teacher:\"\"\"\n",
    "math_chatbot = MathChatbot(prompt)\n",
    "math_chatbot.answer(\"9\")\n",
    "math_chatbot = MathChatbot(prompt)\n",
    "math_chatbot.answer(\"9\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
