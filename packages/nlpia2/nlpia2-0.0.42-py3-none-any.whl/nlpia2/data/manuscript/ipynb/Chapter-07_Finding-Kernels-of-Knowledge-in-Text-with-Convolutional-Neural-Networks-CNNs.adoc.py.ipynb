{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d90887d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')  # <1>\n",
    "text = 'right ones in the right order you can nudge the world'\n",
    "doc = nlp(text)\n",
    "df = pd.DataFrame([\n",
    "   {k: getattr(t, k) for k in 'text pos_'.split()}\n",
    "   for t in doc])\n",
    "pd.get_dummies(df, columns=['pos_'], prefix='', prefix_sep='')\n",
    "def corr(a, b):\n",
    "   \"\"\" Compute the Pearson correlation coefficient R \"\"\"\n",
    "   a = a - np.mean(a)\n",
    "   b = b - np.mean(b)\n",
    "   return sum(a * b) / np.sqrt(sum(a*a) * sum(b*b))\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "quote = \"The right word may be effective, but no word was ever\" \\\n",
    "   \" as effective as a rightly timed pause.\"\n",
    "tagged_words = {\n",
    "   t.text: [t.pos_, int(t.pos_ == 'ADV')]  # <1>\n",
    "   for t in nlp(quote)}\n",
    "df_quote = pd.DataFrame(tagged_words, index=['POS', 'ADV'])\n",
    "print(df_quote)\n",
    "inpt = list(df_quote.loc['ADV'])\n",
    "print(inpt)\n",
    "kernel = [.5, .5]  # <1>\n",
    "output = []\n",
    "for i in range(len(inpt) - 1):  # <2>\n",
    "   z = 0\n",
    "   for k, weight in enumerate(kernel):  # <3>\n",
    "       z = z + weight * inpt[i + k]\n",
    "   output.append(z)\n",
    "print(f'inpt:\\n{inpt}')\n",
    "print(f'len(inpt): {len(inpt)}')\n",
    "print(f'output:\\n{[int(o) if int(o)==o else o for o in output]}')\n",
    "print(f'len(output): {len(output)}')\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 120  # <1>\n",
    "import seaborn as sns\n",
    "sns.set_theme('paper')  # <2>\n",
    "df = pd.DataFrame([inpt, output], index=['inpt', 'output']).T\n",
    "ax = df.plot(style=['+-', 'o:'], linewidth=3)\n",
    "def convolve(inpt, kernel):\n",
    "   output = []\n",
    "   for i in range(len(inpt) - len(kernel) + 1):  # <1>\n",
    "       output.append(\n",
    "           sum(\n",
    "               [\n",
    "                   inpt[i + k] * kernel[k]\n",
    "                   for k in range(len(kernel))  # <2>\n",
    "               ]\n",
    "           )\n",
    "       )\n",
    "   return output\n",
    "tags = 'ADV ADJ VERB NOUN'.split()\n",
    "tagged_words = [\n",
    "   [tok.text] + [int(tok.pos_ == tag) for tag in tags]  # <1>\n",
    "   for tok in nlp(quote)]  # <2>\n",
    "df = pd.DataFrame(tagged_words, columns=['token'] + tags).T\n",
    "print(df)\n",
    "import torch\n",
    "x = torch.tensor(\n",
    "    df.iloc[1:].astype(float).values,\n",
    "    dtype=torch.float32)  # <1>\n",
    "x = x.unsqueeze(0) # <2>\n",
    "kernel = pd.DataFrame(\n",
    "          [[1, 0, 0.],\n",
    "           [0, 0, 0.],\n",
    "           [0, 1, 0.],\n",
    "           [0, 0, 1.]], index=tags)\n",
    "print(kernel)\n",
    "kernel = torch.tensor(kernel.values, dtype=torch.float32)\n",
    "kernel = kernel.unsqueeze(0)  # <1>\n",
    "conv = torch.nn.Conv1d(in_channels=4,\n",
    "                    out_channels=1,\n",
    "                    kernel_size=3,\n",
    "                    bias=False)\n",
    "conv.load_state_dict({'weight': kernel})\n",
    "print(conv.weight)\n",
    "y = np.array(conv.forward(x).detach()).squeeze()\n",
    "df.loc['y'] = pd.Series(y)\n",
    "df\n",
    "from nlpia2.init import maybe_download\n",
    "url = 'https://upload.wikimedia.org/wikipedia/' \\\n",
    "filepath = maybe_download(url)  # <1>\n",
    "print(filepath)\n",
    "from scipy.io import wavfile\n",
    "sample_rate, audio = wavfile.read(filepath)\n",
    "print(f'sample_rate: {sample_rate}')\n",
    "print(f'audio:\\n{audio}')\n",
    "pd.options.display.max_rows = 7\n",
    "audio = audio[:sample_rate * 2]  # <1>\n",
    "audio = np.abs(audio - audio.max() / 2) - .5  # <2>\n",
    "audio = audio / audio.max()  # <3>\n",
    "audio = audio[::sample_rate // 400]  # <4>\n",
    "audio = pd.Series(audio, name='audio')\n",
    "audio.index = 1000 * audio.index / sample_rate  # <5>\n",
    "audio.index.name = 'time (ms)'\n",
    "print(f'audio:\\n{audio}')\n",
    "kernel = [-1] * 24 + [1] * 24 + [-1] * 24  # <1>\n",
    "kernel = pd.Series(kernel, index=2.5 * np.arange(len(kernel)))\n",
    "kernel.index.name = 'Time (ms)'\n",
    "ax = kernel.plot(linewidth=3, ylabel='Kernel weight')\n",
    "kernel = np.array(kernel) / sum(np.abs(kernel))  # <1>\n",
    "pad = [0] * (len(kernel) // 2)  # <2>\n",
    "isdot = convolve(audio.values, kernel)\n",
    "isdot =  np.array(pad[:-1] + list(isdot) + pad)  # <3>\n",
    "df = pd.DataFrame()\n",
    "df['audio'] = audio\n",
    "df['isdot'] = isdot - isdot.min()\n",
    "ax = df.plot()\n",
    "isdot = np.convolve(audio.values, kernel, mode='same')  # <1>\n",
    "df['isdot'] = isdot - isdot.min()\n",
    "ax = df.plot()\n",
    "def describe_model(model):  # <1>\n",
    "    state = model.state_dict()\n",
    "    names = state.keys()\n",
    "    weights = state.values()\n",
    "    params = model.parameters()\n",
    "    df = pd.DataFrame()\n",
    "    df['name'] = list(state.keys())\n",
    "    df['all'] = p.numel(),\n",
    "    df['learned'] = [\n",
    "        p.requires_grad  # <2>\n",
    "        for p in params],  # <3>\n",
    "    size=p.size(),\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
