stages:
  - setup
  - static-analysis
  - tests
  - package
  - publish

variables:
  BUILD_IMAGE_PATH: ${CI_REGISTRY_IMAGE}/build-image:${CI_COMMIT_SHORT_SHA}
  BUILD_IMAGE_VENV_PATH: /venv

  FLIT_ROOT_INSTALL: 1
  GIT_STRATEGY: clone
  GIT_DEPTH: "0"
  BUILDHARNESS_LOG_LEVEL: debug

  PROJECT_NAME: build-harness

  PYPI_API_USER: __token__

  # Don't forget to update the coverage threshold in .pre-commit-config.yaml
  UNITTEST_COVERAGE_THRESHOLD: 90

  VENV_BIN: /venv/bin

  # python: 3.8-slim
  PYTHON_IMAGE_ID: "@sha256:f8a12edddd4fb9c9fd38cd7147c5861a596dee5a4852b6bded3d1d6e2c8987bd"


workflow:
  rules:
    # NOTE: Gitlab-CI conditionals are not strictly shell compliant and must
    #       not use curly brackets.
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: '$CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS'
      when: never
    - if: '$CI_PIPELINE_SOURCE == "push"'


.declare-artifacts: &declare-artifacts
  artifacts:
    expire_in: 1 week
    paths:
      - dist/


.blueskyjunkie-runner-selection:
  tags:
    # select the custom asgard runner(s)
    - blueskyjunkie


.build-harness-target:
  image: ${BUILD_IMAGE_PATH}
  script:
    - |
      ${VENV_BIN}/build-harness \
        --log-console-enable \
        --log-file-enable \
        --log-level ${BUILDHARNESS_LOG_LEVEL} \
        ${TARGET}


.git-work-around:
  before_script:
    # https://gitlab.com/gitlab-org/gitlab/-/issues/350100#note_946527787
    # HACK This is a workaround for the GitLab Runner bug
    #      <https://gitlab.com/gitlab-org/gitlab/-/issues/350100>.
    # If we are on CI,
    # and we are (supposed to be) building a branch,
    # and the SHA of that branch is given
    # and the branch to be built does not exist, locally,
    # create it,
    # check it out,
    # and set its remote tracking branch, if available.
    # NOTE This should also work on local machines,
    #      GitHub Actions and other CI systems,
    #      as there it should result in a no-op,
    #      because the `CI_*` variables will not be set,
    #      and the branch will already exist.
    - |
      if \
          [ -n "$CI" ] && \
          [ -n "$CI_COMMIT_BRANCH" ] && \
          [ -n "$CI_COMMIT_SHA" ] && \
          ! git show-ref --verify --quiet "refs/heads/$CI_COMMIT_BRANCH"
      then
          git branch "$CI_COMMIT_BRANCH" "$CI_COMMIT_SHA"
          git checkout "$CI_COMMIT_BRANCH"
          # Sets the upstream branch, if it exists
          if git show-ref --verify --quiet "refs/remotes/origin/$CI_COMMIT_BRANCH"
          then
              git branch --set-upstream-to="origin/$CI_COMMIT_BRANCH"
          fi
      fi


.pyenv-setup:
  before_script:
    - |
      command -v pyenv >/dev/null || export PATH="${PYENV_ROOT}/bin:${PATH}"
      eval "$(pyenv init -)"
      pyenv shell ${python_version}
      python3 --version
      /venv/bin/python3 --version


check-dockerfile:
  artifacts:
    name: "$CI_JOB_NAME artifacts from $CI_PROJECT_NAME on $CI_COMMIT_REF_SLUG"
    expire_in: 1 day
    when: always
    reports:
      codequality:
        - "reports/*"
    paths:
      - "reports/*"
  image:
    name: hadolint/hadolint:2.5.0-debian
  stage: setup

  script:
    - mkdir -p reports
    - |
      hadolint \
        -f gitlab_codeclimate \
        "${CI_PROJECT_DIR}/docker/ci/Dockerfile" \
        > "reports/hadolint-$(md5sum ${CI_PROJECT_DIR}/docker/ci/Dockerfile | cut -d" " -f1).json"


construct-build-image:
  # https://docs.gitlab.com/ee/ci/docker/using_kaniko.html
  # Run this build on Gitlab shared runners since it is IO intensive.
  image:
    name: gcr.io/kaniko-project/executor:debug
    entrypoint: [ "" ]
  stage: setup
  variables:
    KANIKO_DOCKER_DIR: /kaniko/.docker

  script:
    - mkdir -p "${KANIKO_DOCKER_DIR}"
    - echo "{\"auths\":{\"$CI_REGISTRY\":{\"username\":\"$CI_REGISTRY_USER\",\"password\":\"$CI_REGISTRY_PASSWORD\"}}}" > "${KANIKO_DOCKER_DIR}/config.json"
    - |
      /kaniko/executor \
        --build-arg venv_path="${BUILD_IMAGE_VENV_PATH}" \
        --build-arg project_dir="${CI_PROJECT_DIR}" \
        --build-arg project_name="${PROJECT_NAME}" \
        --context "${CI_PROJECT_DIR}" \
        --dockerfile "${CI_PROJECT_DIR}/docker/ci/Dockerfile" \
        --destination "${BUILD_IMAGE_PATH}"


package-debug:
  image: python${PYTHON_IMAGE_ID}
  stage: setup
  script:
    - apt-get update
    - |
      for x in $(cat docker/ci/apt1_requirements.txt); do \
        apt-cache policy ${x}; \
      done
      for x in $(cat docker/ci/apt2_requirements.txt); do \
        apt-cache policy ${x}; \
      done


formatting-check:
  extends:
    - .build-harness-target
  stage: static-analysis
  variables:
    TARGET: formatting --check


all-check:
  extends:
    - .build-harness-target
  stage: static-analysis
  variables:
    TARGET: static-analysis


flake8-check:
  extends:
    - .build-harness-target
    - .pyenv-setup
  parallel:
    matrix:
      - python_version: [ "3.8", "3.9", "3.10", "3.11" ]
  stage: static-analysis
  variables:
    TARGET: static-analysis --analysis flake8


mypy-check:
  extends:
    - .build-harness-target
    - .pyenv-setup
  parallel:
    matrix:
      - python_version: [ "3.8", "3.9", "3.10", "3.11" ]
  stage: static-analysis
  variables:
    TARGET: static-analysis --analysis mypy


run-tests:
  extends:
    - .build-harness-target
    - .pyenv-setup
  parallel:
    matrix:
      - python_version: [ "3.8", "3.9", "3.10", "3.11" ]
  stage: tests
  # Use Gitlab shared runners (untagged) for IO intensive test
  tags:
  variables:
    TARGET: unit-test


run-tests-coverage:
  extends:
    - .git-work-around
    - .build-harness-target
  stage: tests
  # Use Gitlab shared runners (untagged) for IO intensive test
  tags:
  variables:
    TARGET: unit-test --check ${UNITTEST_COVERAGE_THRESHOLD}

  <<: *declare-artifacts


acceptance-tests:
  extends:
    - .build-harness-target
    - .pyenv-setup
  parallel:
    matrix:
      - python_version: [ "3.8", "3.9", "3.10", "3.11" ]
  stage: tests
  # Use Gitlab shared runners (untagged) for IO intensive test
  tags:
  variables:
    TARGET: acceptance tests --junitxml


acceptance-tags:
  extends:
    - .build-harness-target
  stage: tests
  # Use Gitlab shared runners (untagged) for IO intensive test
  tags:
  variables:
    TARGET: acceptance tags


install-dependency-check:
  # Test that the `build-harness install` target works.
  extends:
    - .build-harness-target
  stage: tests
  variables:
    TARGET: install


install-check:
  # Test that the build-harness project itself can be installed.
  image: ${BUILD_IMAGE_PATH}
  stage: tests
  script:
    - python3 -m venv .venv
    - |
      [[ -d ".venv/bin" ]] || \
      (echo "FAILED: .venv not created" >/dev/stderr; exit 1)
    - .venv/bin/pip install .
    - |
      [[ -f ".venv/bin/build-harness" ]] || \
      (echo "FAILED: ${PROJECT_NAME} not installed" >/dev/stderr; exit 1)


install-template-check:
  # Test that a fresh project instantiation using build-harness can be installed.
  image: ${BUILD_IMAGE_PATH}
  stage: tests
  script:
    - python3 -m venv .venv
    - .venv/bin/pip install . && .venv/bin/build-harness bootstrap this_project
    - |
      cd this_project && \
      .venv/bin/pip install . && \
      [[ ! -z ".venv/bin/pip list | grep this-project" ]] || \
      (echo "FAILED: this_project not installed" >/dev/stderr; exit 1)


build-packages:
  artifacts:
    expire_in: 1 week
    paths:
      - dist/
      - build_harness.log
      - release_flow.log
    when: always
  image: ${BUILD_IMAGE_PATH}
  stage: package

  script:
    - ${VENV_BIN}/release-flow --version
    - |
      echo $(${VENV_BIN}/release-flow \
      --log-console-disable \
      --log-file-enable \
      --log-level ${BUILDHARNESS_LOG_LEVEL} \
      --default-branch "${CI_DEFAULT_BRANCH}")
    - |
      export THIS_VERSION=$(${VENV_BIN}/release-flow \
      --log-console-disable \
      --log-file-enable \
      --log-level ${BUILDHARNESS_LOG_LEVEL} \
      --default-branch "${CI_DEFAULT_BRANCH}")
    # log THIS_VERSION to pipeline log for debugging
    - echo "${THIS_VERSION}"
    - |
      ${VENV_BIN}/build-harness \
      --log-console-disable \
      --log-file-enable \
      --log-level ${BUILDHARNESS_LOG_LEVEL} \
      package\
        --release-id "${THIS_VERSION}"


.publish-packages:
  artifacts:
    expire_in: 1 week
    paths:
      - build_harness.log
      - publish_flow.log
    when: always
  image: ${BUILD_IMAGE_PATH}
  needs:
    - job: build-packages
      artifacts: true
  stage: publish

  before_script:
    - |
      export PUBLISH_THIS=$(${VENV_BIN}/publish-flow \
        --log-console-disable \
        --log-file-enable \
        --log-level ${BUILDHARNESS_LOG_LEVEL} \
        --default-branch "${CI_DEFAULT_BRANCH}" \
        --disable-pr-publish "${CI_PIPELINE_SOURCE}")
    # log PUBLISH_THIS to pipeline log for debugging
    - echo ${PUBLISH_THIS}


publish-packages-released:
  extends:
    - .publish-packages
  rules:
    # NOTE: Gitlab-CI conditionals are not strictly shell compliant and must not use
    #       curly brackets.
    - if: '$CI_COMMIT_TAG'
  script:
    # NOTE: specifically using `--password-file` option here with Gitlab-CI file
    # secret variable option.
    - |
      ${VENV_BIN}/build-harness \
        --log-console-enable \
        --log-file-enable \
        --log-level ${BUILDHARNESS_LOG_LEVEL} \
        publish \
          --user $PYPI_API_USER \
          --password-file $PYPI_API_TOKEN \
          --publish ${PUBLISH_THIS}


publish-packages-unreleased:
  extends:
    - .publish-packages
  rules:
    # NOTE: Gitlab-CI conditionals are not strictly shell compliant and must not use
    #       curly brackets.
    - if: '$CI_COMMIT_REF_NAME == "main"'
    - if: '$CI_COMMIT_REF_NAME =~ /feature/'
  script:
    # NOTE: specifically using `--password-file` option here with Gitlab-CI file
    #       secret variable option.
    #       hard-code dryrun publish to resolve publish issue.
    #       https://gitlab.com/ci-cd-devops/build_harness/-/issues/32
    - |
      ${VENV_BIN}/build-harness \
        --log-console-enable \
        --log-file-enable \
        --log-level ${BUILDHARNESS_LOG_LEVEL} \
        publish \
          --user $PYPI_API_USER \
          --password-file $TESTPYPI_API_TOKEN \
          --publish dryrun
