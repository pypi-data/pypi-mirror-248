# Textsplitter class

The code splits a document according to its native structure in chapters, sections, etc.
It utilizes python class inheritance, so the list of different types of document-parts
(like chapters, titles, footers, appendix, etc.) that can be identified is easily expanded.

The main functionality is given to the textpart-class (textpart.py). Different 
document types like title, body, etc. can then inherit from textpart and overwrite
the rule-function (selection-rule) that decided whether a textline should be added
to a given part. the textsplitter-class is the master-class that the user can yield to
perform the document-splitting.

After the splitting is done, the code utilizes ChatGPT to generate layered summaries
(summaries of summaries), to summariz ethe document per section, chapter, etc.

## functionality of textpart-class

### Setting parameters: <br />
mypart = textpart() <br />
mypart.set_labelname("mylabel") # to label your class <br />
mypart.set_documentpath("/path/to/doc/") # so the class knows where to find your source document <br />
mypart.set_documentname("mydoc") # so the class knows which document to use (no .pdf-extension!) <br />
mypart.set_outputpath("/path/to/dir/") # all output generated by the class is saved in the directory <br />
mypart.set_histogramsize(100) # decides the granulaity to identify fontsize regions. 100 will work usually OK. <br />
mypart.set_ruleverbosity(0) # Decides how much debugging information is printed on the screen (0 is standard) <br />
mypart.set_verbosetextline("my sentence") # If rule verbosit is at least 1, this will print the process of the selection rule for "my sentence" <br />

### Utilizing the class: <br />
mypart.textgeneration("pdfminer") # to put the text (and other properties) from your document into the class <br />
mypart.calculate_footerboundaries(0) # Calculates the proper cut-offs between headers, footers and body-text in the document. <br />
mypart.export("default") # to write the unedited textual content to a .txt-file <br />
mypart.load() # reads the textual content not from a .pdf file, but from a .txt-file (not needed if textgeneration was called) <br />
mypart.fontsizehist() # to create histograms of all fontsizes that occur in the document <br />
mypart.findfontregions() # (call after fontsizehist) to identify different font regions in the histograms, that can be used for text classification. <br />
mypart.selectfontregion(12.0) # returns fontregion-object where 12.0 (fontsize) is located. <br />
mypart.findregularfontregion() # returns the fontregion-object with the fontsize that occurs most frequently <br />
mypart.fontsize_smallerthenregular(12.0) # returns 'true' is 12.0 is in a region below findregularfontregion() <br />
mypart.fontsize_equalstoregular(12.0) # returns 'true' is 12.0 is in a region equal to findregularfontregion() <br />
mypart.whitelinehist() # to create histograms of all spaces between textlines (whitelines) that occur in the document <br />
mypart.findlineregions() # (call after whitelinehist) to identify different lineregions in the histograms of whitelines, that can be used for text classification. <br />
mypart.selectlineregion(12.0) # returns lineregion-object where 12.0 (whiteline) is located. <br />
mypart.findregularlineregion() # returns the lineregion-object with the whiteline that occurs most frequently <br />
mypart.whiteline_isregular(12.0) # return True if 12.0 is located in the regular lineregion <br />
mypart.whiteline_isbig(12.0) # return True if 12.0 is located in a lineregion above the regular lineregion <br />
mypart.whiteline_issmall(12.0) # return True if 12.0 is located in a lineregion below the regular lineregion, BUT still positive <br />
mypart.whiteline_iszero(12.0) # return True if 12.0 is located in the lineregion that contains 0.0 <br />
mypart.whiteline_isvalid(12.0) # return False if 12.0 is located in a lineregion that does not contain positive numbers. <br />
mypart.whiteline_smallerthenregular(12.0) # return True if 12.0 is located in a lineregion below the regular lineregion, regardless of the sign <br />

### Final notes:
textpart can be used independently, but it is not meant for that. It is meant as a base-class
that other classes can inherit from. Those classes can then use this base functionality to perform
text classification and actually break the document down. for that purpose, there are some functions for overwriting: <br />
mypart.rule(thisline) # returns [false,0] but is meant to be overwritten by a useful selection rule. <br />
mypart.masterrule(thisline) # returns false but is meant to be overwritten by a useful rule. The idea is that masterrule combines different rules. <br />
mypart.fillcontent(thisline) # only adds "some text" to the class content if masterrule returned 'true' <br />
mypart.blindfill(thisline) # always adds "some text" to the class content, regardlesss of masterrule <br />
Here, thisline is a CurrentLine-object where you can store information like textual content, fontsize, etc. (see CurrentLine.py) <br />
<br />

Then, there are also some building blocks that are not a member of the textpart-class, because they do not need the variables in that class: <br />
stringmatch("some text","more text") # returns between 0.0-1.0 on how similar the strings are. <br />
remove_nonletters("some text") # (in regex_expressions) returns the string without all characters (including white spaces) that are not letters. <br />
contains_tablecontentsregex("some text") # (in regex_expressions) returns 'true' if "some text" is likely to be the chapter title of the table of content, based on its character content. <br />
contains_chapterregex("some text") # (in regex_expressions) returns 'true' if "some text" is likely to be a chapter title based on its character content. <br />
contains_sectionregex("some text") # (in regex_expressions) returns 'true' if "some text" is likely to be a section title based on its character content. <br />
contains_subsectionregex("some text") # (in regex_expressions) returns 'true' if "some text" is likely to be a subsection title based on its character content. <br />
contains_subsubsectionregex("some text") # (in regex_expressions) returns 'true' if "some text" is likely to be a subsubsection title based on its character content. <br />
contains_headlines_regex("some text") # (in regex_expressions) returns 'true' if "some text" is likely to be a headline (chapter, section, subsection or subsubsection). <br />
contains_bigroman_enumeration("some text") # (in regex_expressions) returns 'true' if "some text" is likely to be an enumeration (with big roman numbers). <br />
contains_smallroman_enumeration("some text") # (in regex_expressions) returns 'true' if "some text" is likely to be an enumeration (with small roman numbers). <br />
contains_bigletter_enumeration("some text") # (in regex_expressions) returns 'true' if "some text" is likely to be an enumeration (with big letters). <br />
contains_smallletter_enumeration("some text") # (in regex_expressions) returns 'true' if "some text" is likely to be an enumeration (with small letters). <br />
contains_digit_enumeration("some text") # (in regex_expressions) returns 'true' if "some text" is likely to be an enumeration (with digits). <br />
contains_signmark_enumeration("some text") # (in regex_expressions) returns 'true' if "some text" is likely to be an enumeration (with marks (-)). <br />
contains_letter_signing("some text") # (in regex_expressions) returns 'true' if "some text" is liekly to be a letter-signing from a politician. <br />

## functionality of inherited classes:

### Body-class
This class inherits from textpart and overwrites the rule-function, so that it selects textlines that are likely to be part of the body of the document. It does this by selection on font size: the font size should be the one that is most frequently used in the document.

### Title-class
This class inherits from textpart and overwrites the rule-function, so that it selects textlines that are likely to be part of the Title of the document. Not yet developed (returns always [0,false])

### Headlines-class
This class inherits from textpart and overwrites the rule-function, so that it selects textlines that are likely to be titles of chapters, sections and other structure-elements. It does this by primarily utilizing font style & size and whitelines. The content of the textline (using regex_expressions) is used only for support in special cases where the layout is inconclusive.

### Enumeration-class
This class inherits from textpart and overwrites the rule-function, so that it selects textlines that are likely to be part of enumerations or itemizations. It does this by using regex-expressions on the content of the textline (using regex_expressions).

### Footer-class
This class inherits from textpart and overwrites the rule-function, so that it selects textlines that are likely to be part of the header or footer of the document. It does this by selecting on vertical position of the text (above header-boundary, or below footer-boundary), or on font size (smaller then body-text).

### Textalinea-class
This class inherits from textpart. It does not overwrite the rule-function, but adds some more elements to the class (like a textlevel and texttitle), so the class can be used to store a textpart like a chapter. The chapter-title is stored in the texttitle and the content is stored in the inherited elements from textpart. textlevel indicates how deep you are in the document. 0=whole document, 1=chapters, 2=sections, 3=subsections, etc. We also call this a cascade-level. The class does come with three extra member-functions: .printalinea() to print the content of the textpart on the terminal and .compare(textalinea) & .compare_samearray(textalinea) to identify whether two alineas are the same or not. The class also contains parentID (to point to the higher cascade-level this element falls under) and horizontal ordering (to point out the ordering between children from the same parent). 

<br />

The ordinary compare() does not test for equality on the parentID, as parentID's can have different meaning when the two textalinea-elements come from different arrays. compare_samearray() takes the test for equal ParentID's along (for when the elemenst originate from the same array). When you want to test for equality on ParentID for elements from different arrays, use AlineasPresent.py in ../Tests/Tools/.

## Functionality of textsplitter-class

This class inherits from textpart. It adds a body-class, a headlines-class, etc. and an array of textalinea-classes. It also comes with some additional member functions. This class is meant fo direct interaction with the user. It should be called by the user in the following way:

### Setting parameters: <br />
mysplitter = textsplitter() <br />
mysplitter.set_labelname("mylabel") # to label your class <br />
mysplitter.set_documentpath("/path/to/doc/") # so the class knows where to find your source document <br />
mysplitter.set_documentname("mydoc") # so the class knows which document to use (no .pdf-extension!) <br />
mysplitter.set_outputpath("/path/to/dir/") # all output generated by the class is saved in the directory <br />
mysplitter.set_histogramsize(100) # decides the granulaity to identify fontsize regions. 100 will work usually OK. <br />
mysplitter.set_MaxSummaryLength(50) # Sets the guideline for calculating summaries to 50 words. Note: only a guideline, and 50 words for each portion of text insie the request. <br />
mysplitter.set_UseDummySummary(True) # This will simply select the first n words from a text as a summary instead of actually summarizing it. <br />
mysplitter.set_summarization_threshold(50) # This will cause that any tekst of less then 50 words is not summarized, but kept in original form. <br />
mysplitter.set_LanguageModel("text-davinci-003") # Ths will select the language model yielded by ChatGPT to perform the summarization. <br />
mysplitter.set_LanguageChoice("Dutch") # This will specify in which language the summaries are generated: Orginal, Dutch, English. <br />
mysplitter.set_ruleverbosity(0) # Decides how much debugging information is printed on the screen (0 is standard) <br />
mysplitter.set_verbosetextline("my sentence") # If rule verbosit is at least 1, this will print the process of the selection rule for "my sentence" <br />

### Utilizing the class: <br />
mysplitter.textgeneration("pdfminer") # to put the text (and other properties) from your document into the class <br />
mysplitter.calculate_footerboundaries(0) # Calculates the proper cut-offs between headers, footers and body-text in the document. <br />
mysplitter.document_metadata() # To extract meta-data from the document like author, creation date, etc. NOTE: That data should exist to extract it. <br />
mysplitter.read_native_TOC("pdfminer") # to read the intrinsic TOC from a PDF document and store in the class (for reference puposes) <br />
mysplitter.export("default") # to write the unedited textual content to a .txt-file (intermediate result) <br />
mysplitter.fontsizehist() # to create histograms of all fontsizes that occur in the document <br />
mysplitter.findfontregions() # to identify different font regions in the histograms, that can be used for text classification. <br />
mysplitter.passinfo() # to pass all information (parameters, fontsize histograms & regions, etc.) to all elements inside the class like body, textalineas, etc.) <br />
mysplitter.breakdown() # This will actually execute the splitting of the document into different parts (stored in the textalineas-array) <br />
mysplitter.calculatetree() # After calling breakdown, this will calculate the parentID and horzontal ordering of the textalinea-elements (so you obtain the correct tree-structure) <br />
mysplitter.summarize(str)->str # This will call ChatGPT to summarize the given text string. Preferably, keep the native newlines in the input. <br />
Errors = mysplitter.layered_summary() # This will use summarize() and the tree structure to calculate short summaries of each textalinea-element. Errors (int) should be 0. <br />
mysplitter.exportdecisions() # Same as export("default"), but with added information per textline on font size, cascade-level, etc. <br />
mysplitter.exportalineas("default") # Prints the different alineas/textparts identified to a .txt-file (final result inspection). <br />
mysplitter.alineas_to_html() # converst the content of textalineas to a html-readable string (& a file) for visualization purposes (stored in html_visualization). <br />

### Final notes:
Textsplitter has 2 more functions that are not discussed above: rulecomparison(thisline), which returns an enumeration-object and a cascade-level and masterrule(thisline), which returns a boolian. rulecomparison takes all the different rules from the body-class, title-class, etc. and combines them into a single output. So this is the place to take care of dependencies or overlaps between the different selection-rules. masterrule then takes this result and generates a boolian from it, to override the masterrule in the textpart-class. thisline is a CurrentLine-object where you can store information like textual content, fontsize, etc. (see CurrentLine.py) <br />
<br />
To identify where a new textual element type (like footer, title, body, etc.) should be added, run the following command: grep -nr '# NOTE: Add new textparts here!' inside this folder and ALSO inside the ../Test/Script/-folder. On all places, you should adapt the code to integrate your new textual element with the existing code (and, of course, a new python-script with the object itself and its selection-rule should be created as well). <br />
<br />
Textsplitter has an element self.ChatGPT_Key where you can store the key to the ChatGPT-account the class will connect to for text summarization. You can provide your own key, or take one of the keys provided in OpenAI_Keys.py. <br />
<br />
You can also just set documentpath, documentname, outputpath and then run: <br />
mysplitter.standard_params() <br />
mysplitter.process() <br />
To simply do a standard-processing of a document. You can add an integer as input to process, which will determine how much output you get in the terminal. If you punt in -1, you get nothing AND you will no longer receive export-files and a html-portion of a page, no longer a full html-output (so you can ue it in a django-template). <br />
<br />

## Notes on reading text from PDF-documents:

The textgeneration-function from the textpart-class supports different options to extract the text from a pdf:

### pdftotext

This can only be used by calling a shell command, which allows
the user to control the layout-parameter (the python library does not).
We prefer to use the -default option (non_raw_non_physical_layout), 
because that will perserve quite a lot from
the layout, while the multi-column structure is removed. This is desirable,
as keeping a multi-column structure in the .txt file (which is what -layout does)
results in adding sentences to the same line that have nothing to do with each other.
The last of the 3 options (-raw) is undesirable as well, as it removes too much
layout components.
<br />
<br />
NOTE: This tool is not yet fully integrated and does not offer font size or vertical position identification.

### pypdf2

This is another python library that extracts text from PDF files. A PDF basically
contains 'draw text commands', which are interpreted by the reader. What pypdf2
does, is to locate those commands and extract the text. We added this option
to the GenerateTextFile.py script to eperiment with different tools.
<br />
<br />
NOTE: This tool is not yet fully integrated and does not offer font size or vertical position identification.

### pymupdf

A text extractor python library for PDF files. According to the benchmarks[https://github.com/py-pdf/benchmarks]
of different tools, it is extremely fast and reliable. We added this option
to the GenerateTextFile.py script to eperiment with different tools.
<br />
<br />
NOTE: This tool is fully integrated and can be used in combination with all functionality of the textsplitter.

### pdfminer

A python library to also draw text from a pdf. This library has quite a lot of functionality
and different subclasses, which allows it to take much more than only the text. It can extrcat
font sizes, images, font types, etc. At this point, pdfminer is the only method in textpart
that draws fontsizes as well from the pdf. See further documentation at:
[pdfminer](https://pdfminersix.readthedocs.io/en/latest/tutorial/extract_pages.html)
<br />
<br />
To decides which letters form words, which words form line, etc, pdfminer utilizes the class LAParams.
This class contains the following parameters (which can be adapted as is done in textgeneration.py):
* line_overlap – If two characters have more overlap than this they are considered to be
on the same line. The overlap is specified relative to the minimum height of both characters.
* char_margin – If two characters are closer together than this margin they are considered
part of the same line. The margin is specified relative to the width of the character.
* word_margin – If two characters on the same line are further apart than this margin then
they are considered to be two separate words, and an intermediate space will be added for
readability. The margin is specified relative to the width of the character.
* line_margin – If two lines are are close together they are considered to be part of the
same paragraph. The margin is specified relative to the height of a line.
* boxes_flow – Specifies how much a horizontal and vertical position of a text matters
when determining the order of text boxes. The value should be within the range of -1.0
(only horizontal position matters) to +1.0 (only vertical position matters). You can also pass
None to disable advanced layout analysis, and instead return text based on the position of
the bottom left corner of the text box.
* detect_vertical – If vertical text should be considered during layout analysis
* all_texts – If layout analysis should be performed on text in figures

<br />
<br />
NOTE: This tool is fully integrated and can be used in combination with all functionality of the textsplitter.

